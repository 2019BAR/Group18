---
title: "期末資料探索"
author: "第18組"
date: "`r Sys.time()`"
output: 
  html_document:
    highlight: pygments
    theme: flatly
    css: style.css
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
pacman::p_load(magrittr, readr, caTools, ggplot2, dplyr)
```



```{r}
# 資料匯入與清洗
# Z = read_csv("./ta_feng_all_months_merged.csv") %>%
#   setNames(c("date","cust","age","area","cat","prod","qty","cost","price"))
# Z$date = as.Date(Z$date, format="%m/%d/%Y")
# Z$age[is.na(Z$age)] = "na"
# Z$age = factor(Z$age, levels=c(
#   "<25","25-29","30-34","35-39","40-44","45-49","50-54","55-59","60-64",">65","na"), labels=c(
#   "a20","a25","a30","a35","a40","a45","a50","a55","a60","a65","na"
#   )) %>% as.character
# # Z$area = paste0("z",Z$area)
# summary(Z)
```

```{r}
# 去除離群值
# Quantile of Variables
# sapply(Z[,7:9], quantile, prob=c(.99, .999, .9995))
# # Remove Outliers
# Z = subset(Z, qty<=24 & cost<=3800 & price<=4000) 
# nrow(Z)
# Z$tid = group_indices(Z, date, cust) # same customer same day
```

```{r}
# 計算不重復變數的數量
# No. cust, cat, prod, tid
# sapply(Z[c("cust","cat","prod","tid")], n_distinct)
```

```{r}
# 整理交易資料成單一資料
# 因爲同一個顧客購買兩個商品會是兩筆明細
# X = Z %>% group_by(tid) %>% summarise(
#   date = date[1],             # 交易日期  
#   cust = cust[1],             # 顧客 ID
#   age = age[1],               # 顧客 年齡級別
#   area = area[1],             # 顧客 居住區別
#   items = n(),                # 交易項目(總)數
#   pieces = sum(qty),          # 產品(總)件數
#   total = sum(price),         # 交易(總)金額
#   gross = sum(price - cost)   # 毛利
#   ) %>% data.frame
# nrow(X) # 119422 
```


```{r}
# 去除離群值
# Check Quantile & Remove Outliers
# sapply(X[,6:9], quantile, prob=c(.999, .9995, .9999))
# # Remove Outliers
# X = subset(X, items<=62 & pieces<95 & total<16000) # 119328
```

```{r}
# 產生客戶屬性的資料
# 一個客戶這4個月在這間店消費的屬性
# d0 = max(X$date) + 1 # 2001-03-01
# A = X %>% mutate(
#   days = as.integer(difftime(d0, date, units="days"))
#   ) %>%
#   group_by(cust) %>% summarise(
#     r = min(days),      # recency 最近一次距今購買天數
#     s = max(days),      # seniority 第一次距今購買天數
#     f = n(),            # frquency 總共買幾次
#     m = mean(total),    # monetary 平均購買金額
#     rev = sum(total),   # total revenue contribution 總收益
#     raw = sum(gross),   # total gross profit contribution 總毛利
#     age = age[1],       # age group 年齡
#     area = area[1],     # area code 地區
#   )     # 33241
# nrow(A)
```

```{r}
#進行客戶分群，使用預設歐式距離，使用ward法
# hc = A[,2:4]  %>% dist %>% hclust(method = "ward.D2")
# plot(hc)
# k =7
# rect.hclust(hc, k=k, border="red")
# g = cutree(hc,k=k)
# A$cut2_4_7 = g
```

####可以先讀入三個已經整理好並分群的資料框做####
```{r}
# save(A, file="./cut_A.rdata")
# save(X, file="./X.rdata")
# save(Z, file="./Z.rdata")

load("./cut_A.rdata")
load("./X.rdata")
load("./Z.rdata")
# set.seed(1111)
# A$keams = kmeans(scale(A[,2:7]),5)$cluster
```




A 為整理後的客戶來店頻率與平均購買金額等
A_feb 為整理後的客戶來店頻率與平均購買金額且時間在二月之前
Z 為整理原始資料X得到的訂單資料（一個客戶一天一筆）
X 為原始資料，經過去除離群值
X_feb 為原始資料，經過去除離群值且時間在二月之前
```{r}

# 利用原始資料分割成2月之前與
feb01 = as.Date("2001-02-01")
X_feb = subset(X, date < feb01)    # 618212
nrow(X_feb) # 617316

# 二月份有購買的資料
feb = filter(X, date>= feb01) %>% group_by(cust) %>% 
  summarise(amount = sum(total))

```

利用分割後的資料X_feb，計算這三個月有購買的客戶資料
```{r}
d0 = max(X_feb$date) + 1 # 2001-02-01
A_feb = X_feb %>% mutate(
  days = as.integer(difftime(d0, date, units="days"))
  ) %>% 
  group_by(cust) %>% summarise(
    r = min(days),      # recency
    s = max(days),      # seniority
    f = n(),            # frquency
    m = mean(total),    # monetary
    rev = sum(total),   # total revenue contribution
    raw = sum(gross),   # total gross profit contribution
    age = age[1],       # age group
    area = area[1],     # area code
  ) %>% data.frame      # 28584
nrow(A_feb)
```

```{r}

# 標記有購買的客戶，並且提供二月份購買的金額
A_feb = merge(A_feb, feb, by="cust", all.x=T)

A_feb$buy = !is.na(A_feb$amount)

# 覆蓋原始資料Ｘ,Z
# 注意現在資料都是2月之前的資料，非全部4個月的資料
# X = subset(X, cust %in% A_feb$cust & date < as.Date("2001-02-01"))
# Z = subset(Z, cust %in% A_feb$cust & date < as.Date("2001-02-01"))
set.seed(2018); spl = sample.split(A_feb$buy, SplitRatio=0.7)
c(nrow(A_feb), sum(spl), sum(!spl))

## [1] 28584 20008  8576
```

```{r}
A2 = subset(A_feb, buy) %>% mutate_at(c("m","rev","amount"), log10)
n = nrow(A2)
set.seed(2018); spl2 = 1:n %in% sample(1:n, round(0.7*n))
c(nrow(A2), sum(spl2), sum(!spl2))
## [1] 13243  9270  3973
```

### 建立模型

預測下個月（2月份）是否購買的機率
```{r}
# 分割train與test
TR = subset(A_feb, spl)
TS = subset(A_feb, !spl)
```

```{r}
# 利用2:9的欄位來進行預測變數
# TR[,c(2:9, 11)] 指使用這些資料進行預測
# buy ~ .實際上就是使用TR[,2:9]的資料來預測TR[,11]
glm1 = glm(buy ~ ., TR[,c(2:9, 11)], family="binomial") 
summary(glm1)
# 建立預測模型後利用test 資料進行預測，並取得機率
pred =  predict(glm1, TS, type="response")
# 建立混淆矩陣，觀察auc
cm = table(actual = TS$buy, predict = pred > 0.5); cm
acc.ts = cm %>% {sum(diag(.))/sum(.)}; acc.ts          # 0.69998
colAUC(pred, TS$buy)   
```

- 預測下個月購買的金額

A2 為A_feb的與金額相關的資料取log後的結果
```{r}
TR2 = subset(A2, spl2)
TS2 = subset(A2, !spl2)
```

```{r}
# 利用2:6,8:10的欄位來進行預測變數
# TR2[,c(2:6,8:10)] 指使用這些資料進行預測
# amount ~ .實際上就是使用TR[,2:6,8:9]的資料來預測TR[,10]
lm1 = lm(amount ~ ., TR2[,c(2:6,8:10)])
summary(lm1)
```
誤差計算
```{r}
r2.tr = summary(lm1)$r.sq
SST = sum((TS2$amount - mean(TR2$amount))^ 2)
SSE = sum((predict(lm1, TS2) -  TS2$amount)^2)
r2.ts = 1 - (SSE/SST)
c(r2.tr, r2.ts)
```

#### 預測模型
重新讀取原本4個月的資料，進行模型預測
```{r}
load("./X.rdata")
d0 = max(X$date) + 1
# 建立12月到2月的交易資料
B = X %>% 
  filter(date >= as.Date("2000-12-01")) %>% 
  mutate(days = as.integer(difftime(d0, date, units="days"))) %>% 
  group_by(cust) %>% summarise(
    r = min(days),      # recency
    s = max(days),      # seniority
    f = n(),            # frquency
    m = mean(total),    # monetary
    rev = sum(total),   # total revenue contribution
    raw = sum(gross),   # total gross profit contribution
    age = age[1],       # age group
    area = area[1],     # area code
  ) %>% data.frame      # 28584
nrow(B)
```

```{r}
# 預測回購紀機率
B$Buy = predict(glm1, B, type="response")

B2 = B %>% mutate_at(c("m","rev"), log10)
# 預測回購金額
B$Rev = 10^predict(lm1, B2)
```


```{r}
par(mfrow=c(1,2), cex=0.8)
hist(B$Buy,main="ProbRetain", ylab="")
hist(log(B$Rev,10),main="log(PredRevenue)", ylab="")
```


###計算顧客終生價值（CLV）
```{r}
g = 0.5   # (稅前)獲利率
N = 5     # 期數 = 5
d = 0.1   # 利率 = 10%
B$CLV = g * B$Rev * rowSums(sapply(
  0:N, function(i) (B$Buy/(1+d))^i ) )

summary(B$CLV)
```


```{r}
par(mar=c(2,2,3,1), cex=0.8)
hist(log(B$CLV,10), xlab="", ylab="")
```


## 比較各族群的價值

```{r}
# 各族群的平均營收貢獻、保留機率、終生價值
B = merge(B,A[,c(1,12)],by="cust")
sapply(B[,10:12], tapply, B$keams, mean)
```

```{r}
par(mar=c(3,3,4,2), cex=0.8)
boxplot(log(CLV)~keams, B, main="CLV by Groups")
```


這些地區可以表示成未來可以加強行銷重點
```{r} 
# 顯示各地區平均購買的金額
tapply(A_feb$rev, A_feb$area, mean) %>% barplot(las=2)
abline(h = mean(A_feb$rev), col='red')
```


可以了解資料中的分群中都買什麼東西，
與其他兩個群組有無重複（有重複！）
如果有，可以進行假設商品，並擬定行銷計畫
把群組都當作目標客群
```{r}
# 整理商品資料成一筆
mix = merge(Z,A[,c(1,11,12)],by="cust")

P = mix %>% group_by(keams,prod) %>% summarise(
  num = n(),
  price = price[1]/qty[1]
) %>% top_n(n = 10,wt = num)
# P$prod = factor(P$prod)
# levels(P$prod) = 1:27
# P$prod
```


```{r}
library(reshape2)
library(d3heatmap)

dtm = dcast(P,formula = keams~prod,value.var = "price")
row.names(dtm) = dtm$keams
termDocMatrix = as.matrix(dtm[,-1])
termDocMatrix[is.na(termDocMatrix)] = 0
d3heatmap(termDocMatrix,colors = "Blues")

# 取log後的結果
termDocMatrix = log(termDocMatrix)
termDocMatrix[termDocMatrix == -Inf] = 0
d3heatmap(termDocMatrix,colors = "Greens",cexRow = 0.7)
```
了解分群顧客有哪些特性
第2群顧客最近剛消費過
且算是本店的首次購買的顧客居多
頻率雖然不高
```{r}
A$logm = log(A$m)
par(cex = 0.9)
par(family="黑體-繁 中黑")

A[,c(2:5)] %>% scale %>% as.data.frame %>%  split(.,A$keams) %>% sapply(colMeans) %>% 
  barplot(beside=T, col=rainbow(4))
legend("bottomright", c("最近一次消費距今", "第一次購買日期距今", "購買頻率","平均購買金額"),fill=rainbow(4),cex=0.8)
```

第2群顧客奇怪的是購買商品數量較雜
購買商品種類繁多，但是都沒有一定的趨勢

```{r}
mix %>% filter(cut2_4_7==2) %>% group_by(prod) %>% summarise(n = n()) %>% arrange(desc(n))
```


```{r}
group_by(A, keams) %>% summarise(
  recent=mean(r), 
  freq=mean(f), 
  money=mean(m), 
  size=n() ) %>% 
  mutate( revenue = size*money/1000 )  %>% 
  filter(size > 1) %>% 
  ggplot(aes(x=freq, y=money)) +
  geom_point(aes(size=revenue, col=recent),alpha=0.5) +
  scale_size(range=c(4,20)) +
  scale_color_gradient(low="green",high="red") +
  scale_x_log10() + scale_y_log10() + 
  geom_text(aes(label = size ),size=3) +
  theme_bw() + guides(size=F) +
  labs(title="Customer Segements",
       subtitle="(bubble_size:revenue_contribution; text:group_size)",
       color="Recency") +
  xlab("Frequency (log)") + ylab("Average Transaction Amount (log)")
```

畫出顧客分群

```{r}
group_by(A, keams) %>% summarise(
  recent=mean(r), 
  freq=mean(f), 
  money=mean(m), 
  size=n() ) %>% 
  mutate( revenue = size*money/1000 )  %>% 
  filter(size > 1) %>% 
  ggplot(aes(x=freq, y=money)) +
  geom_point(aes(size=revenue, col=recent),alpha=0.5) +
  scale_size(range=c(4,20)) +
  scale_color_gradient(low="green",high="red") +
  scale_x_log10() + scale_y_log10() + 
  geom_text(aes(label = keams ),size=3) +
  theme_bw() + guides(size=F) +
  labs(title="Customer Segements",
       subtitle="(bubble_size:revenue_contribution; text:group_size)",
       color="Recency") +
  xlab("Frequency (log)") + ylab("Average Transaction Amount (log)")
```

```{r}
mix = merge(Z,A[,c(1,12)],by = "cust")
mix$weeks = format(mix$date,"%u")
group_by(mix,keams,weeks) %>% 
  summarise(count = n()) %>%
  group_by(keams) %>% 
  mutate(sum = sum(count),ratio = count/sum) %>% 
  ggplot(aes(x=as.factor(keams),y = ratio,fill = weeks)) + geom_bar(stat = "identity")

```

了解客戶這4個月最常來的星期
並且計算顧客所屬群組的常去星期幾買東西的總和
```{r}
A_often_come = group_by(mix,cust,weeks) %>% 
  summarise(
    count = n(),
    label = keams[1]
  ) %>% group_by(cust) %>% top_n(1,wt = count)

table(A_often_come$weeks,A_often_come$label) %>% as.data.frame.matrix() %>% d3heatmap::d3heatmap(colors = "Greens")
```

2001-01-21除夕的前一天，那天的購買次數是這４個月最高的

```{r}
X %>% group_by(date) %>% summarise(
  count = n()
) %>% arrange(desc(count)) 
```

```{r}
temp3 = Z %>% group_by(prod) %>% summarise(s = sum(qty))
arrange(temp3, s)
```


```{r}
product_z = Z %>% group_by(date,prod,area) %>% 
  summarise(
    sum = sum(qty)
  )
product_top = product_z %>% group_by(prod) %>% summarise(
  sum = sum(sum)
) %>% arrange(desc(sum))
product_top %>% head(n = 10) %>% ggplot(aes(x = prod,y = sum,fill=prod)) + geom_bar(stat = "identity",alpha = 0.8) +
  theme(axis.text.x = element_text(angle = 25))

```

```{r}
product_top3 = product_z %>% filter(prod %in% c("4714981010038","4710421090059","4711271000014")) %>% group_by(date,prod) %>% summarise(
  sum = sum(sum)
)

ggplot(product_top3,aes(x = date,y = sum,fill=prod)) + geom_bar(stat = "identity",alpha = 0.8) + labs(y = "Sales", x = "")


```

```{r}
library(reshape2)
product_top3 %>% mutate(weeks = format(date,"%u")) %>% group_by(prod,weeks) %>% summarise(sum = sum(sum)) %>%
  acast(formula = prod~weeks,value.var = "sum") %>% d3heatmap::d3heatmap(col="PiYG",Colv = F)
```

```{r}
Z1 = group_by(Z,prod) %>% summarize(
  pro = sum(qty * (price - cost))
)
Z1 = arrange(Z1,desc(pro)) 
Z1 %>% head(n = 10) %>% ggplot(aes(x = prod,y = pro,fill=prod)) + geom_bar(stat = "identity",alpha = 0.8) +
  theme(axis.text.x = element_text(angle = 25))

```

